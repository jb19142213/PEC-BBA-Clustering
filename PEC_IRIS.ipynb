{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_centers(X, c, random_state=None):\n",
    "    \"\"\"\n",
    "    Initialize cluster centers by filling missing values with column means\n",
    "    and picking random rows as initial centers.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    n, s = X.shape\n",
    "    mask = ~np.isnan(X)\n",
    "    col_means = np.where(mask, X, np.nan).mean(axis=0)\n",
    "    X_filled = np.where(mask, X, col_means)\n",
    "    idx = rng.choice(n, size=c, replace=False)\n",
    "    return X_filled[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_partial_distances(X, V, mask):\n",
    "    \"\"\"\n",
    "    Compute squared partial distances d_ij^2 between each object and each center:\n",
    "      d_ij^2 = sum_p lambda_ip (x_ip - v_jp)^2\n",
    "    where lambda_ip = 1 if observed, 0 if missing.\n",
    "    \"\"\"\n",
    "    # X_zero has 0 for missing values to avoid nan propagation\n",
    "    X_zero = np.where(mask, X, 0.0)\n",
    "    # shape: (n, c, s)\n",
    "    diff = X_zero[:, None, :] - V[None, :, :]\n",
    "    # mask3: (n, 1, s) -> broadcast to (n, c, s)\n",
    "    mask3 = mask[:, None, :]\n",
    "    diff_masked = diff * mask3\n",
    "    d2 = (diff_masked ** 2).sum(axis=2)  # (n, c)\n",
    "    return d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_memberships(d2, beta, delta2):\n",
    "    \"\"\"\n",
    "    Update membership masses m_ij and m_i_empty (for outliers) given distances d2.\n",
    "    Uses formulas (10) in the paper with numeric stabilisation.\n",
    "    \"\"\"\n",
    "    power = -1.0 / (beta - 1.0)\n",
    "    # avoid division by zero\n",
    "    d2_safe = d2 + 1e-12\n",
    "    tmp = d2_safe ** power  # shape (n, c)\n",
    "    delta_term = (delta2 + 1e-12) ** power\n",
    "    denom = tmp.sum(axis=1, keepdims=True) + delta_term  # shape (n, 1)\n",
    "    m = tmp / denom  # m_ij\n",
    "    m_empty = delta_term / denom.squeeze()  # m_i∅\n",
    "    return m, m_empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_centers(X, mask, M, beta):\n",
    "    \"\"\"\n",
    "    Update cluster centers via formula (11).\n",
    "    \"\"\"\n",
    "    n, s = X.shape\n",
    "    c = M.shape[1]\n",
    "    V = np.zeros((c, s), dtype=float)\n",
    "    m_beta = M ** beta  # (n, c)\n",
    "    X_valid = np.where(np.isnan(X), 0, X)  # Replace nan with 0 for calculation\n",
    "    valid_mask = (~np.isnan(X)).astype(float)  # 1 where not nan, 0 where nan\n",
    "\n",
    "    for j in range(c):\n",
    "        w = m_beta[:, j:j+1] * mask  # (n, s)\n",
    "        w_valid = w * valid_mask     # zero out weights where X is nan\n",
    "        num = (w_valid * X_valid).sum(axis=0)    # (s,)\n",
    "        den = w_valid.sum(axis=0)                # (s,)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            v_j = np.where(den > 0, num / den, 0.0)\n",
    "        V[j] = v_j\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  Step 1: Preliminary partial-distance evidential clustering\n",
    "# ============================================================\n",
    "\n",
    "def preliminary_pec(X, c, beta=2.0, eps=1e-4, max_iter=200, random_state=None):\n",
    "    \"\"\"\n",
    "    Step 1: Perform evidential clustering with partial distances (no imputation).\n",
    "    Returns:\n",
    "      V          : final cluster centers (c, s)\n",
    "      M          : mass matrix for singleton clusters (n, c)\n",
    "      m_empty    : mass vector for outlier (n,)\n",
    "      info       : dict with Lambda sets, completeness, and preliminary labels\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    n, s = X.shape\n",
    "    mask = ~np.isnan(X)  # True if observed\n",
    "\n",
    "    # 1) Initialize centers\n",
    "    V = _init_centers(X, c, random_state=random_state)\n",
    "\n",
    "    # 2) Iterative optimization of objective (5)\n",
    "    for _ in range(max_iter):\n",
    "        V_prev = V.copy()\n",
    "        # distances and delta^2 (7)\n",
    "        d2 = _compute_partial_distances(X, V, mask)  # (n, c)\n",
    "        delta2 = d2.sum() / (c * n)\n",
    "        # memberships (10)\n",
    "        M, m_empty = _update_memberships(d2, beta, delta2)\n",
    "        # centers (11)\n",
    "        V = _update_centers(X, mask, M, beta)\n",
    "        # check convergence\n",
    "        if np.linalg.norm(V - V_prev) < eps:\n",
    "            break\n",
    "\n",
    "    # 3) Compute threshold phi (14)\n",
    "    m_bar = M.mean(axis=1, keepdims=True)   # (n,1)\n",
    "    phi = ((M - m_bar) ** 2).mean()         # scalar\n",
    "\n",
    "    # 4) Compute Lambda_i sets and preliminary labels\n",
    "    Lambda = []\n",
    "    is_complete = mask.all(axis=1)  # (n,)\n",
    "\n",
    "    prelim_type = np.empty(n, dtype=object)\n",
    "    prelim_cluster = np.full(n, -1, dtype=int)  # singleton cluster index or -1\n",
    "    # 'noise' = pure outlier; 'singleton' = definite cluster; 'meta' = meta-cluster; 'uncertain_incomplete' = go to Step 2\n",
    "\n",
    "    for i in range(n):\n",
    "        # extended masses: index 0 = empty, 1..c = clusters 0..c-1\n",
    "        masses = np.concatenate(([m_empty[i]], M[i]))  # shape (c+1,)\n",
    "        max_idx = np.argmax(masses)\n",
    "        max_val = masses[max_idx]\n",
    "\n",
    "        Lambda_i = set()\n",
    "        for j in range(c + 1):\n",
    "            if abs(max_val - masses[j]) < phi:\n",
    "                if j == 0:\n",
    "                    Lambda_i.add('empty')\n",
    "                else:\n",
    "                    Lambda_i.add(j - 1)\n",
    "        Lambda.append(Lambda_i)\n",
    "\n",
    "        # classify preliminarily\n",
    "        if len(Lambda_i) == 0:\n",
    "            prelim_type[i] = 'noise'\n",
    "            prelim_cluster[i] = -1\n",
    "        elif len(Lambda_i) == 1 and 'empty' in Lambda_i:\n",
    "            prelim_type[i] = 'noise'\n",
    "            prelim_cluster[i] = -1\n",
    "        elif len(Lambda_i) == 1 and 'empty' not in Lambda_i:\n",
    "            # definite singleton cluster\n",
    "            prelim_type[i] = 'singleton'\n",
    "            (g,) = Lambda_i\n",
    "            prelim_cluster[i] = g\n",
    "        else:\n",
    "            # ambiguous between >=2 elements\n",
    "            if is_complete[i]:\n",
    "                prelim_type[i] = 'meta'\n",
    "                prelim_cluster[i] = -1\n",
    "            else:\n",
    "                prelim_type[i] = 'uncertain_incomplete'\n",
    "                prelim_cluster[i] = -1\n",
    "\n",
    "    info = {\n",
    "        \"mask\": mask,\n",
    "        \"Lambda\": Lambda,\n",
    "        \"is_complete\": is_complete,\n",
    "        \"prelim_type\": prelim_type,\n",
    "        \"prelim_cluster\": prelim_cluster,\n",
    "        \"delta2\": delta2\n",
    "    }\n",
    "    return V, M, m_empty, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "#  Step 2: Multiple imputation + DST redistribution\n",
    "# ============================================================\n",
    "\n",
    "def _single_membership_from_distances(d2_row, beta, delta2):\n",
    "    \"\"\"\n",
    "    Compute membership (m_j, m_empty) for a single object given distances d2_row (shape (c,)).\n",
    "    \"\"\"\n",
    "    power = -1.0 / (beta - 1.0)\n",
    "    d2_safe = d2_row + 1e-12\n",
    "    tmp = d2_safe ** power\n",
    "    delta_term = (delta2 + 1e-12) ** power\n",
    "    denom = tmp.sum() + delta_term\n",
    "    m = tmp / denom\n",
    "    m_empty = delta_term / denom\n",
    "    return m, m_empty\n",
    "\n",
    "\n",
    "def _softmax_negative(distances):\n",
    "    \"\"\"\n",
    "    Turn distances (list/array) into reliability factors via softmax(-d).\n",
    "    \"\"\"\n",
    "    d = np.asarray(distances, dtype=float)\n",
    "    m = d.min()\n",
    "    exp_vals = np.exp(-(d - m))  # stabilise\n",
    "    s = exp_vals.sum()\n",
    "    if s == 0:\n",
    "        return np.ones_like(distances) / len(distances)\n",
    "    return exp_vals / s\n",
    "\n",
    "\n",
    "def _build_bba_from_membership(m_clusters, m_empty, c):\n",
    "    \"\"\"\n",
    "    Build a basic belief assignment (BBA) dict from membership vector and outlier mass.\n",
    "    Keys:\n",
    "      'empty' -> m_empty\n",
    "      0..c-1  -> m_clusters[j]\n",
    "    \"\"\"\n",
    "    bba = {'empty': float(m_empty)}\n",
    "    for j in range(c):\n",
    "        bba[j] = float(m_clusters[j])\n",
    "    return bba\n",
    "\n",
    "\n",
    "def _discount_bba_with_meta(bba, alpha, cluster_candidates, c):\n",
    "    \"\"\"\n",
    "    Apply reliability discounting as in (20)-(21), placing uncertainty\n",
    "    on the meta-cluster corresponding to cluster_candidates.\n",
    "    Returns a new BBA with keys: 'empty', 0..c-1, 'meta'.\n",
    "    \"\"\"\n",
    "    # original masses\n",
    "    m_empty = bba.get('empty', 0.0)\n",
    "    m_clusters = np.array([bba.get(j, 0.0) for j in range(c)], dtype=float)\n",
    "\n",
    "    m_tilde = {}\n",
    "    m_tilde['empty'] = m_empty\n",
    "    # discounted singletons\n",
    "    m_tilde_clusters = alpha * m_clusters\n",
    "    for j in range(c):\n",
    "        m_tilde[j] = float(m_tilde_clusters[j])\n",
    "\n",
    "    # meta mass\n",
    "    meta_mass = 1.0 - m_empty - m_tilde_clusters.sum()\n",
    "    # clip for numerical stability\n",
    "    meta_mass = max(0.0, min(1.0, meta_mass))\n",
    "    m_tilde['meta'] = meta_mass\n",
    "    return m_tilde\n",
    "\n",
    "\n",
    "def _subset_from_key(key, cluster_candidates_set):\n",
    "    \"\"\"\n",
    "    Map a BBA key to a subset of Ω:\n",
    "      'empty' -> empty set\n",
    "      int j   -> {j}\n",
    "      'meta'  -> cluster_candidates_set\n",
    "    \"\"\"\n",
    "    if key == 'empty':\n",
    "        return frozenset()\n",
    "    elif key == 'meta':\n",
    "        return frozenset(cluster_candidates_set)\n",
    "    else:\n",
    "        return frozenset([key])\n",
    "\n",
    "\n",
    "def _key_from_subset(subset, cluster_candidates_set):\n",
    "    \"\"\"\n",
    "    Map subset back to a key. We only allow:\n",
    "      ∅       -> 'empty'\n",
    "      {j}     -> j\n",
    "      full Λ  -> 'meta'\n",
    "    \"\"\"\n",
    "    if len(subset) == 0:\n",
    "        return 'empty'\n",
    "    if subset == frozenset(cluster_candidates_set):\n",
    "        return 'meta'\n",
    "    if len(subset) == 1:\n",
    "        (j,) = tuple(subset)\n",
    "        return j\n",
    "    # In this implementation, we don't create new meta-clusters besides Λ;\n",
    "    # any other subset is ignored (it should not appear in our restricted setup).\n",
    "    return None\n",
    "\n",
    "\n",
    "def _fuse_two_bbas(bba1, bba2, cluster_candidates_set, c):\n",
    "    \"\"\"\n",
    "    Fuse two BBAs using the modified Dempster–Shafer rule (22)-(23).\n",
    "    Keys: 'empty', 0..c-1, 'meta'.\n",
    "    \"\"\"\n",
    "    keys = ['empty'] + list(range(c)) + ['meta']\n",
    "\n",
    "    # compute conflict K\n",
    "    K = 0.0\n",
    "    for B in keys:\n",
    "        for C in keys:\n",
    "            if B == 'empty' or C == 'empty':\n",
    "                continue\n",
    "            setB = _subset_from_key(B, cluster_candidates_set)\n",
    "            setC = _subset_from_key(C, cluster_candidates_set)\n",
    "            inter = setB & setC\n",
    "            if len(inter) == 0:\n",
    "                K += bba1.get(B, 0.0) * bba2.get(C, 0.0)\n",
    "\n",
    "    denom = 1.0 - K + 1e-12\n",
    "\n",
    "    # fuse non-empty subsets\n",
    "    num = {k: 0.0 for k in keys}\n",
    "    for B in keys:\n",
    "        for C in keys:\n",
    "            setB = _subset_from_key(B, cluster_candidates_set)\n",
    "            setC = _subset_from_key(C, cluster_candidates_set)\n",
    "            inter = setB & setC\n",
    "            keyA = _key_from_subset(inter, cluster_candidates_set)\n",
    "            if keyA is None:\n",
    "                continue\n",
    "            num[keyA] += bba1.get(B, 0.0) * bba2.get(C, 0.0)\n",
    "\n",
    "    fused = {k: 0.0 for k in keys}\n",
    "    # empty case special formula\n",
    "    fused['empty'] = (\n",
    "        bba1.get('empty', 0.0)\n",
    "        + bba2.get('empty', 0.0)\n",
    "        - bba1.get('empty', 0.0) * bba2.get('empty', 0.0)\n",
    "    ) / denom\n",
    "\n",
    "    for k in keys:\n",
    "        if k == 'empty':\n",
    "            continue\n",
    "        fused[k] = num[k] / denom\n",
    "\n",
    "    return fused\n",
    "\n",
    "\n",
    "def _fuse_bba_list(bba_list, cluster_candidates_set, c):\n",
    "    \"\"\"\n",
    "    Fuse a list of BBAs with the above fusion rule.\n",
    "    \"\"\"\n",
    "    if not bba_list:\n",
    "        return None\n",
    "    fused = bba_list[0]\n",
    "    for bba in bba_list[1:]:\n",
    "        fused = _fuse_two_bbas(fused, bba, cluster_candidates_set, c)\n",
    "    return fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pec(X, c, beta=2.0, eps=1e-4, max_iter=200, random_state=None):\n",
    "    \"\"\"\n",
    "    Full PEC algorithm (Steps 1 and 2) as described in the paper:\n",
    "      - Partial-distance evidential clustering (no imputation)\n",
    "      - Multiple imputation for uncertain incomplete objects\n",
    "      - DST-based reliability discounting and evidence fusion\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Data matrix with np.nan for missing values.\n",
    "    c : int\n",
    "        Number of specific clusters.\n",
    "    beta : float, optional\n",
    "        Fuzzifier (usually 2).\n",
    "    eps : float, optional\n",
    "        Convergence tolerance for centers.\n",
    "    max_iter : int, optional\n",
    "        Maximum number of iterations in Step 1.\n",
    "    random_state : int or None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_assignments : list\n",
    "        For each object i: a tuple describing its decision:\n",
    "          ('noise',)\n",
    "          ('singleton', j)\n",
    "          ('meta', (j1, j2, ...))\n",
    "    final_bbas : list of dict\n",
    "        For each object, its final BBA over:\n",
    "          'empty', 0..c-1, optionally 'meta'\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    n, s = X.shape\n",
    "\n",
    "    # Step 1: preliminary evidential clustering via partial distances\n",
    "    V, M, m_empty, info = preliminary_pec(\n",
    "        X, c, beta=beta, eps=eps, max_iter=max_iter, random_state=random_state\n",
    "    )\n",
    "    mask = info[\"mask\"]\n",
    "    Lambda = info[\"Lambda\"]\n",
    "    is_complete = info[\"is_complete\"]\n",
    "    prelim_type = info[\"prelim_type\"]\n",
    "    prelim_cluster = info[\"prelim_cluster\"]\n",
    "    delta2 = info[\"delta2\"]\n",
    "\n",
    "    # Build neighbor pools: complete objects firmly assigned to singleton clusters\n",
    "    cluster_neighbors = {g: [] for g in range(c)}\n",
    "    for i in range(n):\n",
    "        if is_complete[i] and prelim_type[i] == 'singleton':\n",
    "            g = prelim_cluster[i]\n",
    "            cluster_neighbors[g].append(i)\n",
    "\n",
    "    # Step 2: handle uncertain incomplete objects via multiple imputation + DST\n",
    "    final_bbas = [None] * n\n",
    "    final_assignments = [None] * n\n",
    "\n",
    "    # Precompute once: base BBAs from Step 1 for all objects\n",
    "    base_bbas = []\n",
    "    for i in range(n):\n",
    "        bba = _build_bba_from_membership(M[i], m_empty[i], c)\n",
    "        base_bbas.append(bba)\n",
    "\n",
    "    for i in range(n):\n",
    "        # Case 1: uncertain incomplete -> full PEC redistribution\n",
    "        if prelim_type[i] == 'uncertain_incomplete':\n",
    "            # candidate clusters (ignore 'empty')\n",
    "            cluster_candidates = sorted([j for j in Lambda[i] if j != 'empty'])\n",
    "            if len(cluster_candidates) < 2:\n",
    "                # not enough info -> fall back to base BBA\n",
    "                bba_final = base_bbas[i]\n",
    "                final_bbas[i] = bba_final\n",
    "            else:\n",
    "                # multiple imputation: one version per candidate cluster\n",
    "                Xi = X[i].copy()\n",
    "                Xi_mask = mask[i]\n",
    "                Xi_zero = np.where(Xi_mask, Xi, 0.0)\n",
    "\n",
    "                bba_versions = []\n",
    "                reliabilities_dist = []\n",
    "\n",
    "                for g in cluster_candidates:\n",
    "                    neigh_idx = cluster_neighbors[g]\n",
    "                    if len(neigh_idx) == 0:\n",
    "                        continue  # cannot impute from this cluster\n",
    "\n",
    "                    neighbors = X[neigh_idx]  # (K, s)\n",
    "                    neigh_mask = mask[neigh_idx]\n",
    "                    # distances for weights (15)\n",
    "                    # use Xi's observed dims only\n",
    "                    diffs = (neighbors - Xi_zero) * Xi_mask  # broadcast Xi_mask (s,)\n",
    "                    dists = np.sqrt((diffs ** 2).sum(axis=1))  # (K,)\n",
    "                    # if Xi has no observed dims, give equal weights\n",
    "                    if Xi_mask.sum() == 0:\n",
    "                        theta = np.ones(len(neigh_idx)) / len(neigh_idx)\n",
    "                    else:\n",
    "                        # weights (16)\n",
    "                        exp_vals = np.exp(-dists)\n",
    "                        s_exp = exp_vals.sum()\n",
    "                        if s_exp == 0:\n",
    "                            theta = np.ones(len(neigh_idx)) / len(neigh_idx)\n",
    "                        else:\n",
    "                            theta = exp_vals / s_exp\n",
    "\n",
    "                    # impute missing attributes using (17)\n",
    "                    Xi_imputed = Xi.copy()\n",
    "                    missing_dims = ~Xi_mask\n",
    "                    if missing_dims.any():\n",
    "                        Xi_imputed[missing_dims] = (theta[:, None] * neighbors[:, missing_dims]).sum(axis=0)\n",
    "\n",
    "                    # compute membership for imputed version using centers V (one step of (10))\n",
    "                    Xi_imputed = Xi_imputed[None, :]  # shape (1, s)\n",
    "                    Xi_imputed_mask = np.ones_like(Xi_imputed, dtype=bool)\n",
    "                    d2_row = _compute_partial_distances(Xi_imputed, V, Xi_imputed_mask)[0]\n",
    "                    m_clusters_i, m_empty_i = _single_membership_from_distances(d2_row, beta, delta2)\n",
    "\n",
    "                    # build BBA for this version\n",
    "                    bba_i_g = _build_bba_from_membership(m_clusters_i, m_empty_i, c)\n",
    "\n",
    "                    # compute reliability distance (18)-(19) using neighbors' BBAs\n",
    "                    # here we measure in the space of {empty} + singletons\n",
    "                    vec_i = np.array(\n",
    "                        [bba_i_g['empty']] + [bba_i_g[j] for j in range(c)],\n",
    "                        dtype=float\n",
    "                    )\n",
    "                    dist_sum = 0.0\n",
    "                    for k_idx in neigh_idx:\n",
    "                        bba_k = base_bbas[k_idx]\n",
    "                        vec_k = np.array(\n",
    "                            [bba_k['empty']] + [bba_k[j] for j in range(c)],\n",
    "                            dtype=float\n",
    "                        )\n",
    "                        dist_sum += np.linalg.norm(vec_i - vec_k)\n",
    "                    bba_versions.append(bba_i_g)\n",
    "                    reliabilities_dist.append(dist_sum)\n",
    "\n",
    "                if len(bba_versions) == 0:\n",
    "                    # could not build any version -> fall back\n",
    "                    bba_final = base_bbas[i]\n",
    "                    final_bbas[i] = bba_final\n",
    "                else:\n",
    "                    # compute reliability factors alpha via softmax(-distance)\n",
    "                    alphas = _softmax_negative(reliabilities_dist)\n",
    "                    # discount each BBA and put ignorance on meta-cluster Λ̂_i\n",
    "                    cluster_candidates_set = set(cluster_candidates)\n",
    "                    discounted_list = []\n",
    "                    for bba_v, alpha in zip(bba_versions, alphas):\n",
    "                        discounted = _discount_bba_with_meta(\n",
    "                            bba_v, alpha, cluster_candidates, c\n",
    "                        )\n",
    "                        discounted_list.append(discounted)\n",
    "\n",
    "                    # fuse them using modified DS rule\n",
    "                    bba_final = _fuse_bba_list(\n",
    "                        discounted_list, cluster_candidates_set, c\n",
    "                    )\n",
    "                    final_bbas[i] = bba_final\n",
    "\n",
    "        # Case 2: all other points -> use simple evidential interpretation of Step 1\n",
    "        else:\n",
    "            bba_final = base_bbas[i].copy()\n",
    "            # If complete and ambiguous (meta), push mass of ambiguous clusters to 'meta'\n",
    "            if prelim_type[i] == 'meta':\n",
    "                cluster_candidates = sorted([j for j in Lambda[i] if j != 'empty'])\n",
    "                cluster_candidates_set = set(cluster_candidates)\n",
    "                if cluster_candidates:\n",
    "                    # collect mass for meta from those candidates\n",
    "                    meta_mass = sum(bba_final.get(j, 0.0) for j in cluster_candidates)\n",
    "                    for j in cluster_candidates:\n",
    "                        bba_final[j] = 0.0\n",
    "                    bba_final['meta'] = bba_final.get('meta', 0.0) + meta_mass\n",
    "            final_bbas[i] = bba_final\n",
    "\n",
    "        # now derive final assignment from final_bbas[i]\n",
    "        bba_i = final_bbas[i]\n",
    "        # ensure keys exist\n",
    "        mass_empty = bba_i.get('empty', 0.0)\n",
    "        masses_clusters = np.array([bba_i.get(j, 0.0) for j in range(c)])\n",
    "        mass_meta = bba_i.get('meta', 0.0)\n",
    "\n",
    "        # choose argmax over {empty, singletons, meta}\n",
    "        elems = ['empty'] + list(range(c)) + ['meta']\n",
    "        vals = [mass_empty] + list(masses_clusters) + [mass_meta]\n",
    "        k_max = elems[int(np.argmax(vals))]\n",
    "\n",
    "        if k_max == 'empty':\n",
    "            final_assignments[i] = ('noise',)\n",
    "        elif k_max == 'meta':\n",
    "            # for meta we can retrieve candidates from Lambda[i] (excluding 'empty')\n",
    "            cluster_candidates = sorted([j for j in Lambda[i] if j != 'empty'])\n",
    "            final_assignments[i] = ('meta', tuple(cluster_candidates))\n",
    "        else:\n",
    "            final_assignments[i] = ('singleton', int(k_max))\n",
    "\n",
    "    return final_assignments, final_bbas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of rows to have missing values\n",
    "n_rows = df.shape[0]\n",
    "n_missing = int(0.3* n_rows)\n",
    "\n",
    "# Randomly select row indices\n",
    "missing_rows = np.random.choice(df.index, size=n_missing, replace=False)\n",
    "\n",
    "# For each selected row, randomly set 1 or more columns (excluding 'target') to NaN\n",
    "for row in missing_rows:\n",
    "    n_cols_missing = np.random.randint(1, len(iris.feature_names) + 1)\n",
    "    cols_missing = np.random.choice(iris.feature_names, size=n_cols_missing, replace=False)\n",
    "    df.loc[row, cols_missing] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  NaN               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                NaN               3.0                NaN               NaN   \n",
       "146                NaN               2.5                NaN               NaN   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments, bbas=pec(df.drop(\"target\",axis=1), 3, beta=3.0, eps=1e-6, max_iter=400, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"assignments\"]=assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>assignments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>(singleton, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>(singleton, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>(singleton, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>(singleton, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>(singleton, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>(singleton, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>(singleton, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(singleton, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>(singleton, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>(meta, (0, 2))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  NaN               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                NaN               3.0                NaN               NaN   \n",
       "146                NaN               2.5                NaN               NaN   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target     assignments  \n",
       "0         0  (singleton, 1)  \n",
       "1         0  (singleton, 1)  \n",
       "2         0  (singleton, 1)  \n",
       "3         0  (singleton, 1)  \n",
       "4         0  (singleton, 1)  \n",
       "..      ...             ...  \n",
       "145       2  (singleton, 2)  \n",
       "146       2  (singleton, 0)  \n",
       "147       2  (singleton, 2)  \n",
       "148       2  (singleton, 2)  \n",
       "149       2  (meta, (0, 2))  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "createdOn": 1764482555320,
  "creator": "2018509",
  "customFields": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (env offus)",
   "language": "python",
   "name": "py-dku-venv-offus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "modifiedBy": "2018509",
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
